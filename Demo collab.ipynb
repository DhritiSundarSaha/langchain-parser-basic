{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r-tLa_J6XW0K"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U google-genai langchain langchain-google-genai pydantic fastapi uvicorn python-dotenv gradio\n",
        "\n",
        "import os\n",
        "GOOGLE_API_KEY = \"AIzaSyCenaiBSJAjdGwDfswLlYbKMRr-ETD_P6Q\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "assert os.environ[\"GOOGLE_API_KEY\"], \"Set GOOGLE_API_KEY above first!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai"
      ],
      "metadata": {
        "id": "RMhxHyrNX6kA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "SoN2_joHaX4e",
        "outputId": "75f81927-fb53-48ba-c573-feb8ec608c77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.183.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.7.0\n",
            "    Uninstalling google-ai-generativelanguage-0.7.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2328f5638e144a128c69965ecb4dd9e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "API_KEY = \"AIzaSyCenaiBSJAjdGwDfswLlYbKMRr-ETD_P6Q\"\n",
        "\n",
        "try:\n",
        "    genai.configure(api_key=API_KEY)\n",
        "\n",
        "    print(\"‚úÖ Configuration successful!\")\n",
        "    print(\"Fetching available models...\")\n",
        "\n",
        "    models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "\n",
        "    if models:\n",
        "        print(\"\\n‚úÖ API Key is working! Here are some available models:\")\n",
        "        for model in models[:5]:\n",
        "            print(f\" - {model}\")\n",
        "    else:\n",
        "        print(\"‚ùå Could not find any usable models. Check your API key permissions.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An error occurred: {e}\")\n",
        "    print(\"\\nüí° Please check the following:\")\n",
        "    print(\"   1. Is your API key correct and active?\")\n",
        "    print(\"   2. Is the Google Generative AI API enabled in your Google Cloud project?\")\n",
        "    print(\"   3. Do you have an active internet connection?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "zyzpKhhKaYh-",
        "outputId": "6229cf1f-ba1c-4ac9-bff3-c8bdc0103f4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration successful!\n",
            "Fetching available models...\n",
            "\n",
            "‚úÖ API Key is working! Here are some available models:\n",
            " - models/gemini-2.5-pro-preview-03-25\n",
            " - models/gemini-2.5-flash-preview-05-20\n",
            " - models/gemini-2.5-flash\n",
            " - models/gemini-2.5-flash-lite-preview-06-17\n",
            " - models/gemini-2.5-pro-preview-05-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U google-generativeai pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ60K8gyb8Pu",
        "outputId": "5de82b3a-180d-4d1d-c130-89ecaeea7a34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.183.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic[email]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX02I3QxdRM3",
        "outputId": "1baaabe7-140c-4dcd-e845-99214a8cb941"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic[email] in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic[email]) (0.4.2)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email])\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email])\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->pydantic[email]) (3.10)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, email-validator\n",
            "Successfully installed dnspython-2.8.0 email-validator-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, EmailStr\n",
        "\n",
        "class Person(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    email: EmailStr\n"
      ],
      "metadata": {
        "id": "3HA8ukN5d76B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pydantic[email] phonenumbers google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0-qdfCdd9QN",
        "outputId": "de40d282-8ddd-4e1d-b4d7-4a574394bf33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m165.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json\n",
        "import google.generativeai as genai\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "from pydantic import BaseModel, EmailStr, Field, ValidationError, field_validator\n",
        "import phonenumbers\n",
        "\n",
        "API_KEY = \"AIzaSyCenaiBSJAjdGwDfswLlYbKMRr-ETD_P6Q\"\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "-0GFhCSzeaaW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\"\n",
        "def normalize_phone(number_raw: str, default_region: str = \"IN\") -> str:\n",
        "    if not number_raw or not isinstance(number_raw, str):\n",
        "        raise ValueError(\"Phone must be a non-empty string\")\n",
        "\n",
        "    cleaned = re.sub(r\"[^\\d+]\", \"\", number_raw)"
      ],
      "metadata": {
        "id": "H93e8VSxeq7o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_phone(number_raw: str, default_region: str = \"IN\") -> str:\n",
        "    if not number_raw or not isinstance(number_raw, str):\n",
        "        raise ValueError(\"Phone must be a non-empty string\")\n",
        "    cleaned = re.sub(r\"[^\\d+]\", \"\", number_raw)\n",
        "    try:\n",
        "        if cleaned.startswith(\"+\"):\n",
        "            parsed = phonenumbers.parse(cleaned, None)\n",
        "        else:\n",
        "            parsed = phonenumbers.parse(cleaned, default_region)\n",
        "    except phonenumbers.NumberParseException as e:\n",
        "        raise ValueError(f\"Invalid phone format: {e}\")\n",
        "\n",
        "    if not phonenumbers.is_possible_number(parsed) or not phonenumbers.is_valid_number(parsed):\n",
        "        raise ValueError(\"Phone number is not valid\")\n",
        "\n",
        "    return phonenumbers.format_number(parsed, phonenumbers.PhoneNumberFormat.E164)\n"
      ],
      "metadata": {
        "id": "gv-q0VfUe26T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U google-generativeai langchain langchain-google-genai pydantic[email] phonenumbers gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nnHdjoXfRJe",
        "outputId": "9b424d63-66d2-4702-f96d-349f470be5e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json\n",
        "import google.generativeai as genai\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "\n",
        "from pydantic import BaseModel, EmailStr, Field, ValidationError, field_validator\n",
        "import phonenumbers\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser"
      ],
      "metadata": {
        "id": "DdS6X-TkiYnT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "Ka_hFYo9iee1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=MODEL_ID)"
      ],
      "metadata": {
        "id": "YK-_AU0einxv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_phone(number_raw: str, default_region: str = \"IN\") -> str:\n",
        "    if not number_raw or not isinstance(number_raw, str):\n",
        "        raise ValueError(\"Phone must be a non-empty string\")\n",
        "\n",
        "    cleaned = re.sub(r\"[^\\d+]\", \"\", number_raw)\n",
        "\n",
        "    try:\n",
        "        if cleaned.startswith(\"+\"):\n",
        "            parsed = phonenumbers.parse(cleaned, None)\n",
        "        else:\n",
        "            parsed = phonenumbers.parse(cleaned, default_region)\n",
        "    except phonenumbers.NumberParseException as e:\n",
        "        raise ValueError(f\"Invalid phone format: {e}\")\n",
        "\n",
        "    if not phonenumbers.is_possible_number(parsed) or not phonenumbers.is_valid_number(parsed):\n",
        "        raise ValueError(\"Phone number is not valid\")\n",
        "\n",
        "    return phonenumbers.format_number(parsed, phonenumbers.PhoneNumberFormat.E164)\n",
        "\n",
        "class Person(BaseModel):\n",
        "    name: str = Field(..., min_length=1)\n",
        "    age: int = Field(..., ge=0, le=120)\n",
        "    email: Optional[EmailStr] = None\n",
        "    phone: Optional[str] = Field(default=None, description=\"E.164 phone number like +919876543210\")\n",
        "\n",
        "    @field_validator(\"phone\")\n",
        "    @classmethod\n",
        "    def _validate_phone(cls, v):\n",
        "        if v is None or v == \"\":\n",
        "            return None\n",
        "        return normalize_phone(v, default_region=\"IN\")\n"
      ],
      "metadata": {
        "id": "mm8zUVuGipfz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMMON_DOMAIN_FIXES = {\n",
        "    \"gamil.com\": \"gmail.com\",\n",
        "    \"gmial.com\": \"gmail.com\",\n",
        "    \"gmail.con\": \"gmail.com\",\n",
        "    \"gnail.com\": \"gmail.com\",\n",
        "    \"yaho.com\": \"yahoo.com\",\n",
        "    \"yhoo.com\": \"yahoo.com\",\n",
        "    \"outlok.com\": \"outlook.com\",\n",
        "    \"hotmal.com\": \"hotmail.com\",\n",
        "    \"icloud,com\": \"icloud.com\",\n",
        "}"
      ],
      "metadata": {
        "id": "feiKqpzXiwkM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regex_autocorrect_email(raw: str) -> str:\n",
        "    if not raw:\n",
        "        return raw\n",
        "    s = raw.strip()\n",
        "    s = s.replace(\" \", \"\")\n",
        "    s = s.replace(\"(at)\", \"@\").replace(\"[at]\", \"@\").replace(\"{at}\", \"@\").replace(\"at\", \"@\") if \"@\" not in s else s\n",
        "    s = s.replace(\"(dot)\", \".\").replace(\"[dot]\", \".\").replace(\"{dot}\", \".\")\n",
        "    s = s.replace(\",\", \".\")\n",
        "    if s.count(\"@\") > 1:\n",
        "        parts = s.split(\"@\")\n",
        "        s = parts[0] + \"@\" + \"\".join(parts[1:])\n",
        "    if \"@\" in s:\n",
        "        local, domain = s.split(\"@\", 1)\n",
        "        domain = domain.lower().rstrip(\".\")\n",
        "        for bad, good in COMMON_DOMAIN_FIXES.items():\n",
        "            if domain == bad:\n",
        "                domain = good\n",
        "        s = f\"{local}@{domain}\"\n",
        "    s = re.sub(r\"[;,\\.\\s]+$\", \"\", s)\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "eRnG2JFVi6x7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_suggest_email(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Ask Gemini to suggest a corrected email. Returns suggested email or 'UNKNOWN'.\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel(MODEL_ID)\n",
        "    prompt = f\"\"\"\n",
        "You are an email-correction function.\n",
        "Given a possibly mistyped email, return ONLY the corrected email (no quotes, no extra text).\n",
        "If you cannot confidently correct, return EXACTLY: UNKNOWN\n",
        "\n",
        "Examples:\n",
        "Input: \"raj_22 at gmail,com\" -> raj_22@gmail.com\n",
        "Input: \"alice@@example..com\" -> alice@example.com\n",
        "Input: \"foo at bar\" -> UNKNOWN\n",
        "\n",
        "Input: \"{raw}\"\n",
        "Output:\n",
        "\"\"\"\n",
        "    resp = model.generate_content(prompt)\n",
        "    suggestion = (getattr(resp, \"text\", \"\") or \"\").strip()\n",
        "    m = re.search(r\"[A-Za-z0-9_.+\\-]+@[A-Za-z0-9\\-]+\\.[A-Za-z0-9.\\-]+\", suggestion)\n",
        "    return m.group(0) if m else (\"UNKNOWN\" if \"UNKNOWN\" in suggestion.upper() else suggestion)\n"
      ],
      "metadata": {
        "id": "45HeO52zi-xv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_with_autocorrect(payload: Dict[str, Any]) -> Tuple[Optional[Person], Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validate payload into Person. If email fails: try regex correction, then LLM correction.\n",
        "    Returns (person_or_none, info) where info reports corrections and any errors.\n",
        "    \"\"\"\n",
        "    info = {\"email_correction\": None, \"llm_email_correction\": None, \"errors\": None}\n",
        "    try:\n",
        "        person = Person.model_validate(payload)\n",
        "        return person, info\n",
        "    except ValidationError as e:\n",
        "        info[\"errors\"] = str(e)\n",
        "\n",
        "    data = dict(payload)\n",
        "    raw_email = data.get(\"email\")\n",
        "\n",
        "    if raw_email:\n",
        "        # regex pass\n",
        "        rx = regex_autocorrect_email(raw_email)\n",
        "        if rx != raw_email:\n",
        "            data[\"email\"] = rx\n",
        "            info[\"email_correction\"] = {\"from\": raw_email, \"to\": rx}\n",
        "            try:\n",
        "                person = Person.model_validate(data)\n",
        "                info[\"errors\"] = None\n",
        "                return person, info\n",
        "            except ValidationError as e:\n",
        "                info[\"errors\"] = str(e)\n",
        "\n",
        "        # LLM pass\n",
        "        suggestion = llm_suggest_email(raw_email)\n",
        "        if suggestion and suggestion != \"UNKNOWN\" and suggestion != raw_email:\n",
        "            data[\"email\"] = suggestion\n",
        "            info[\"llm_email_correction\"] = {\"from\": raw_email, \"to\": suggestion}\n",
        "            try:\n",
        "                person = Person.model_validate(data)\n",
        "                info[\"errors\"] = None\n",
        "                return person, info\n",
        "            except ValidationError as e:\n",
        "                info[\"errors\"] = str(e)\n",
        "\n",
        "    return None, info"
      ],
      "metadata": {
        "id": "x13fIWY3jDHB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LANGCHAIN CHAIN: extract Person from free text"
      ],
      "metadata": {
        "id": "JvIWrXpKjKj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = PydanticOutputParser(pydantic_object=Person)\n",
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a strict information extractor. Return ONLY valid JSON matching the schema.\"),\n",
        "    (\"human\", \"Extract a Person (name, age, email?, phone?) from this text:\\n\\n{text}\\n\\n{format_instructions}\")\n",
        "])\n",
        "\n",
        "extract_chain = prompt | llm | parser  # returns Person if the model followed instructions perfectly\n",
        "\n",
        "def try_extract_person_from_text(text: str) -> Optional[Person]:\n",
        "    \"\"\"\n",
        "    Ask the model to produce a Person; if it fails, return None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return extract_chain.invoke({\"text\": text, \"format_instructions\": format_instructions})\n",
        "    except Exception:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "OqorDoNWjGsZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def respond(user_msg: str) -> str:\n",
        "    # 1) Try structured extraction\n",
        "    maybe_person = try_extract_person_from_text(user_msg)\n",
        "\n",
        "    if maybe_person:\n",
        "        # 2) Run auto-correct validation (handles phone/email issues)\n",
        "        person, info = validate_with_autocorrect(maybe_person.model_dump())\n",
        "        if person:\n",
        "            msg = \"‚úÖ Extracted & validated contact:\\n\" + json.dumps(person.model_dump(), indent=2)\n",
        "            if info.get(\"email_correction\"):\n",
        "                msg += \"\\n\\n(note: regex email fix) \" + json.dumps(info[\"email_correction\"])\n",
        "            if info.get(\"llm_email_correction\"):\n",
        "                msg += \"\\n\\n(note: LLM email fix) \" + json.dumps(info[\"llm_email_correction\"])\n",
        "            return msg\n",
        "        else:\n",
        "            return \"‚ö†Ô∏è I tried to extract a contact but validation failed:\\n\" + (info.get(\"errors\") or \"Unknown error\")\n",
        "\n",
        "    # 3) Fallback to normal chat if no structured data looks present\n",
        "    r = llm.invoke([(\"human\", user_msg)])\n",
        "    return r.content\n"
      ],
      "metadata": {
        "id": "HsdMAJevjOxk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(respond(\"Hi, I'm Raj 22, email: raj_22 at gmail,com, phone 09876 543210\"))\n",
        "print()\n",
        "print(respond(\"hello there!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwp7-ml-jRy3",
        "outputId": "44278b42-139e-40c5-b53d-f2cb99bbbc84"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted & validated contact:\n",
            "{\n",
            "  \"name\": \"Raj\",\n",
            "  \"age\": 22,\n",
            "  \"email\": \"raj_22@gmail.com\",\n",
            "  \"phone\": \"+919876543210\"\n",
            "}\n",
            "\n",
            "‚úÖ Extracted & validated contact:\n",
            "{\n",
            "  \"name\": \"Unknown\",\n",
            "  \"age\": 0,\n",
            "  \"email\": null,\n",
            "  \"phone\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(title=\"Gemini + LangChain + Pydantic: Contacts Chat\") as demo:\n",
        "    gr.Markdown(\"## Extract contacts from messages ‚Äî with phone validation & email auto-correct\")\n",
        "    chat = gr.Chatbot(height=380)\n",
        "    msg = gr.Textbox(placeholder=\"Try: I'm Tina, 27, mail tina@@example..com, phone +91-98765-43210\", label=\"Message\")\n",
        "    clear = gr.ClearButton([msg, chat])\n",
        "\n",
        "    def on_submit(user_input, history):\n",
        "        bot_reply = respond(user_input)\n",
        "        history = history + [[user_input, bot_reply]]\n",
        "        return \"\", history\n",
        "\n",
        "    msg.submit(on_submit, [msg, chat], [msg, chat])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "on4BFsxxjU_x",
        "outputId": "8679556b-5bc1-4fb2-81db-e4b17da04434"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3154113349.py:5: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chat = gr.Chatbot(height=380)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://26a0d7199a901145e7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26a0d7199a901145e7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXhpLgfsjk0B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}